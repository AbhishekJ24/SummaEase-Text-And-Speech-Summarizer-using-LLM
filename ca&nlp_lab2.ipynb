{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "NXWYZTdTRu49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyzAlSg8WeHj",
        "outputId": "c78a86f4-f277-4dbf-d44f-e7651a016fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def perform_stemming(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # Initialize the Porter Stemmer\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    # Perform stemming on each word\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "    return \" \".join(stemmed_words)\n",
        "\n",
        "def perform_lemmatization(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # Initialize the WordNet Lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Perform lemmatization on each word\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    return \" \".join(lemmatized_words)\n",
        "\n",
        "# Get user input\n",
        "user_input = input(\"Enter a sentence: \")\n",
        "\n",
        "# Perform stemming\n",
        "stemmed_result = perform_stemming(user_input)\n",
        "print(\"Stemmed Result:\", stemmed_result)\n",
        "\n",
        "# Perform lemmatization\n",
        "lemmatized_result = perform_lemmatization(user_input)\n",
        "print(\"Lemmatized Result:\", lemmatized_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3h7ZfujYK8Z",
        "outputId": "016b1839-e31f-4b71-c851-182ccb591884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: He is a good boy. She is a good girl.\n",
            "Stemmed Result: he is a good boy . she is a good girl .\n",
            "Lemmatized Result: He is a good boy . She is a good girl .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Initialize Python porter stemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "example_sentence = \"He is a good boy. She is a good girl. Boy and Girl are good\"\n",
        "\n",
        "# Remove punctuation\n",
        "example_sentence_no_punct = example_sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "\n",
        "# Create tokens\n",
        "word_tokens = word_tokenize(example_sentence_no_punct)\n",
        "\n",
        "# Perform stemming\n",
        "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n",
        "for word in word_tokens:\n",
        "    print (\"{0:20}{1:20}\".format(word, ps.stem(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih7GSaxyZt8N",
        "outputId": "cd4c0604-9021-45ab-852e-f95c22c609d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--Word--            --Stem--            \n",
            "He                  he                  \n",
            "is                  is                  \n",
            "a                   a                   \n",
            "good                good                \n",
            "boy                 boy                 \n",
            "She                 she                 \n",
            "is                  is                  \n",
            "a                   a                   \n",
            "good                good                \n",
            "girl                girl                \n",
            "Boy                 boy                 \n",
            "and                 and                 \n",
            "Girl                girl                \n",
            "are                 are                 \n",
            "good                good                \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag, word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def perform_lemmatization(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # Initialize the WordNet Lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Perform lemmatization on each word\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    return \" \".join(lemmatized_words)\n",
        "\n",
        "def get_pos_tags(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # Get POS tags for each word\n",
        "    pos_tags = pos_tag(words)\n",
        "\n",
        "    return pos_tags\n",
        "\n",
        "# Get user input\n",
        "user_input = input(\"Enter a sentence: \")\n",
        "\n",
        "# Perform lemmatization\n",
        "lemmatized_result = perform_lemmatization(user_input)\n",
        "print(\"Lemmatized Result:\", lemmatized_result)\n",
        "\n",
        "# Get POS tags\n",
        "pos_tags_result = get_pos_tags(user_input)\n",
        "print(\"POS Tags:\", pos_tags_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liGNAeFmbzqW",
        "outputId": "07e2e43b-3991-4eaa-f7d1-5c187a493e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence: He is a good boy. She is a good girl . Boy and girl are good.\n",
            "Lemmatized Result: He is a good boy . She is a good girl . Boy and girl are good .\n",
            "POS Tags: [('He', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('boy', 'NN'), ('.', '.'), ('She', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('girl', 'NN'), ('.', '.'), ('Boy', 'NNP'), ('and', 'CC'), ('girl', 'NN'), ('are', 'VBP'), ('good', 'JJ'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def remove_stopwords(sentence):\n",
        "    # Tokenize the sentence into words\n",
        "    words = word_tokenize(sentence)\n",
        "\n",
        "    # Get the English stop words from NLTK\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Remove stop words from the tokenized words\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Get user input for the number of sentences\n",
        "num_sentences = int(input(\"Enter the number of sentences: \"))\n",
        "\n",
        "# Get user input for each sentence\n",
        "sentences = []\n",
        "for i in range(num_sentences):\n",
        "    user_input = input(f\"Enter sentence {i+1}: \")\n",
        "    sentences.append(user_input)\n",
        "\n",
        "# Remove stop words from each sentence\n",
        "filtered_sentences = [remove_stopwords(sentence) for sentence in sentences]\n",
        "\n",
        "# Print the results\n",
        "print(\"\\nOriginal Sentences:\")\n",
        "for i, sentence in enumerate(sentences):\n",
        "    print(f\"Sentence {i+1}: {sentence}\")\n",
        "\n",
        "print(\"\\nSentences after removing stop words:\")\n",
        "for i, filtered_sentence in enumerate(filtered_sentences):\n",
        "    print(f\"Filtered Sentence {i+1}: {filtered_sentence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huiwQ0X_wMPN",
        "outputId": "5ba52521-8049-4d62-b7bf-83c6d82373c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of sentences: 3\n",
            "Enter sentence 1: He is a good boy.\n",
            "Enter sentence 2: She is a good girl.\n",
            "Enter sentence 3: Boy and Girl are good.\n",
            "\n",
            "Original Sentences:\n",
            "Sentence 1: He is a good boy.\n",
            "Sentence 2: She is a good girl.\n",
            "Sentence 3: Boy and Girl are good.\n",
            "\n",
            "Sentences after removing stop words:\n",
            "Filtered Sentence 1: good boy .\n",
            "Filtered Sentence 2: good girl .\n",
            "Filtered Sentence 3: Boy Girl good .\n"
          ]
        }
      ]
    }
  ]
}