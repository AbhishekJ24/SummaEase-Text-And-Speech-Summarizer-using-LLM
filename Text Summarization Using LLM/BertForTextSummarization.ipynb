{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x1Ih5D5lW7U",
        "outputId": "2b7bab62-6eca-4762-a33f-cb83efcde6f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "zwOf6w6olch5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data for training\n",
        "sample_data = [\n",
        "    {'input_text': 'This is an example input text.', 'target_text': 'Example summary.'},\n",
        "    {'input_text': 'Another input text for summarization.', 'target_text': 'Summary of the second text.'},\n",
        "    # Add more samples as needed\n",
        "]"
      ],
      "metadata": {
        "id": "SMz1vv20ldJ8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Access input and target text from the sample dictionary\n",
        "        sample = self.data[idx]\n",
        "        input_text = sample['input_text']\n",
        "        target_text = sample['target_text']\n",
        "\n",
        "        # Tokenize input and target text using the tokenizer\n",
        "        input_encoding = self.tokenizer(input_text, truncation=True, padding='max_length', max_length=512)\n",
        "        target_encoding = self.tokenizer(target_text, truncation=True, padding='max_length', max_length=64)\n",
        "\n",
        "        # Convert tokenized sequences to tensors\n",
        "        input_ids = torch.tensor(input_encoding['input_ids'])\n",
        "        attention_mask = torch.tensor(input_encoding['attention_mask'])\n",
        "        target_ids = torch.tensor(target_encoding['input_ids'])  # Use input_ids for target since it's an autoregressive model\n",
        "\n",
        "        return input_ids, attention_mask, target_ids"
      ],
      "metadata": {
        "id": "FGh35pSyn8eK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of CustomDataset with the sample data\n",
        "dataset = CustomDataset(sample_data)"
      ],
      "metadata": {
        "id": "ybmOgSThpZXd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters and variables\n",
        "batch_size = 2\n",
        "learning_rate = 5e-5\n",
        "num_epochs = 5"
      ],
      "metadata": {
        "id": "zKWfCc09pcrb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')"
      ],
      "metadata": {
        "id": "T4T3pMEtph-w"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataloader\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "n4XYJhThpkQE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)"
      ],
      "metadata": {
        "id": "rdyNCOI0pnQf"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in dataloader:\n",
        "        input_ids, attention_mask, target_ids = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, decoder_input_ids=target_ids[:, :-1])\n",
        "        logits = outputs.logits\n",
        "        loss = torch.nn.functional.cross_entropy(logits.view(-1, logits.shape[-1]), target_ids[:, 1:].reshape(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "id": "Nz21HsZTpppF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference function\n",
        "def generate_summary(input_text):\n",
        "    model.eval()\n",
        "    inputs = dataset.tokenizer([input_text], max_length=1024, return_tensors='pt', truncation=True)\n",
        "    summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=150, early_stopping=True)\n",
        "    summary = dataset.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "tpfYOMSRpuJY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"The rapid advancement of artificial intelligence (AI) has transformed various industries, including healthcare, finance, and transportation. AI technologies such as machine learning and natural language processing are being used to analyze large datasets, automate tasks, and improve decision-making processes. For instance, in healthcare, AI-powered systems can assist doctors in diagnosing diseases more accurately and quickly. In finance, AI algorithms are used for fraud detection and risk assessment. Moreover, in transportation, AI plays a crucial role in the development of autonomous vehicles, leading to safer and more efficient transportation systems. Overall, AI continues to revolutionize industries and has the potential to drive significant innovation and growth in the future\"\n",
        "summary = generate_summary(input_text)\n",
        "\n",
        "# Print the generated summary\n",
        "print(\"Generated Summary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIpQrctzovcJ",
        "outputId": "32a822fa-6f17-408a-d1dd-fd8b60609cc1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary:\n",
            "The rapid advancement of artificial intelligence has transformed various industries, including healthcare, finance, and transportation. In healthcare, AI-powered systems can assist doctors in diagnosing diseases more accurately and quickly. In finance, AI algorithms are used for fraud detection and risk assessment. In transportation, AI plays a crucial role in the development of autonomous vehicles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PBjemVMo_99",
        "outputId": "509a45c5-7ba5-44ec-f68b-6ee754bd3a35"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "790"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6LkSNZ1pC98",
        "outputId": "cdccf2d2-ce2d-4a39-ba4e-96a0e8b6ceb6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "402"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}